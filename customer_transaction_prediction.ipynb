{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>11.4763</td>\n",
       "      <td>-2.3182</td>\n",
       "      <td>12.6080</td>\n",
       "      <td>8.6264</td>\n",
       "      <td>10.9621</td>\n",
       "      <td>3.5609</td>\n",
       "      <td>4.5322</td>\n",
       "      <td>15.2255</td>\n",
       "      <td>3.5855</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.3068</td>\n",
       "      <td>6.6025</td>\n",
       "      <td>5.2912</td>\n",
       "      <td>0.4403</td>\n",
       "      <td>14.9452</td>\n",
       "      <td>1.0314</td>\n",
       "      <td>-3.6241</td>\n",
       "      <td>9.7670</td>\n",
       "      <td>12.5809</td>\n",
       "      <td>-4.7602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>11.8091</td>\n",
       "      <td>-0.0832</td>\n",
       "      <td>9.3494</td>\n",
       "      <td>4.2916</td>\n",
       "      <td>11.1355</td>\n",
       "      <td>-8.0198</td>\n",
       "      <td>6.1961</td>\n",
       "      <td>12.0771</td>\n",
       "      <td>-4.3781</td>\n",
       "      <td>...</td>\n",
       "      <td>8.7830</td>\n",
       "      <td>6.4521</td>\n",
       "      <td>3.5325</td>\n",
       "      <td>0.1777</td>\n",
       "      <td>18.3314</td>\n",
       "      <td>0.5845</td>\n",
       "      <td>9.1104</td>\n",
       "      <td>9.1143</td>\n",
       "      <td>10.8869</td>\n",
       "      <td>-3.2097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>13.5580</td>\n",
       "      <td>-7.9881</td>\n",
       "      <td>13.8776</td>\n",
       "      <td>7.5985</td>\n",
       "      <td>8.6543</td>\n",
       "      <td>0.8310</td>\n",
       "      <td>5.6890</td>\n",
       "      <td>22.3262</td>\n",
       "      <td>5.0647</td>\n",
       "      <td>...</td>\n",
       "      <td>13.1700</td>\n",
       "      <td>6.5491</td>\n",
       "      <td>3.9906</td>\n",
       "      <td>5.8061</td>\n",
       "      <td>23.1407</td>\n",
       "      <td>-0.3776</td>\n",
       "      <td>4.2178</td>\n",
       "      <td>9.4237</td>\n",
       "      <td>8.6624</td>\n",
       "      <td>3.4806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>16.1071</td>\n",
       "      <td>2.4426</td>\n",
       "      <td>13.9307</td>\n",
       "      <td>5.6327</td>\n",
       "      <td>8.8014</td>\n",
       "      <td>6.1630</td>\n",
       "      <td>4.4514</td>\n",
       "      <td>10.1854</td>\n",
       "      <td>-3.1882</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4298</td>\n",
       "      <td>14.7510</td>\n",
       "      <td>1.6395</td>\n",
       "      <td>1.4181</td>\n",
       "      <td>14.8370</td>\n",
       "      <td>-1.9940</td>\n",
       "      <td>-1.0733</td>\n",
       "      <td>8.1975</td>\n",
       "      <td>19.5114</td>\n",
       "      <td>4.8453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>12.5088</td>\n",
       "      <td>1.9743</td>\n",
       "      <td>8.8960</td>\n",
       "      <td>5.4508</td>\n",
       "      <td>13.6043</td>\n",
       "      <td>-16.2859</td>\n",
       "      <td>6.0637</td>\n",
       "      <td>16.8410</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5543</td>\n",
       "      <td>6.3160</td>\n",
       "      <td>1.0371</td>\n",
       "      <td>3.6885</td>\n",
       "      <td>14.8344</td>\n",
       "      <td>0.4467</td>\n",
       "      <td>14.1287</td>\n",
       "      <td>7.9133</td>\n",
       "      <td>16.2375</td>\n",
       "      <td>14.2514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target    var_0   var_1    var_2   var_3    var_4    var_5   var_6  \\\n",
       "0       0   8.9255 -6.7863  11.9081  5.0930  11.4607  -9.2834  5.1187   \n",
       "1       0  11.5006 -4.1473  13.8588  5.3890  12.3622   7.0433  5.6208   \n",
       "2       0   8.6093 -2.7457  12.0805  7.8928  10.5825  -9.0837  6.9427   \n",
       "3       0  11.0604 -2.1518   8.9522  7.1957  12.5846  -1.8361  5.8428   \n",
       "4       0   9.8369 -1.4834  12.8746  6.6375  12.2772   2.4486  5.9405   \n",
       "5       0  11.4763 -2.3182  12.6080  8.6264  10.9621   3.5609  4.5322   \n",
       "6       0  11.8091 -0.0832   9.3494  4.2916  11.1355  -8.0198  6.1961   \n",
       "7       0  13.5580 -7.9881  13.8776  7.5985   8.6543   0.8310  5.6890   \n",
       "8       0  16.1071  2.4426  13.9307  5.6327   8.8014   6.1630  4.4514   \n",
       "9       0  12.5088  1.9743   8.8960  5.4508  13.6043 -16.2859  6.0637   \n",
       "\n",
       "     var_7   var_8   ...     var_190  var_191  var_192  var_193  var_194  \\\n",
       "0  18.6266 -4.9200   ...      4.4354   3.9642   3.1364   1.6910  18.5227   \n",
       "1  16.5338  3.1468   ...      7.6421   7.7214   2.5837  10.9516  15.4305   \n",
       "2  14.6155 -4.9193   ...      2.9057   9.7905   1.6704   1.6858  21.6042   \n",
       "3  14.9250 -5.8609   ...      4.4666   4.7433   0.7178   1.4214  23.0347   \n",
       "4  19.2514  6.2654   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876   \n",
       "5  15.2255  3.5855   ...     -6.3068   6.6025   5.2912   0.4403  14.9452   \n",
       "6  12.0771 -4.3781   ...      8.7830   6.4521   3.5325   0.1777  18.3314   \n",
       "7  22.3262  5.0647   ...     13.1700   6.5491   3.9906   5.8061  23.1407   \n",
       "8  10.1854 -3.1882   ...      1.4298  14.7510   1.6395   1.4181  14.8370   \n",
       "9  16.8410  0.1287   ...      0.5543   6.3160   1.0371   3.6885  14.8344   \n",
       "\n",
       "   var_195  var_196  var_197  var_198  var_199  \n",
       "0  -2.3978   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   2.0339   8.1267   8.7889  18.3560   1.9518  \n",
       "2   3.1417  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -1.2706  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4  -1.5121   3.9267   9.5031  17.9974  -8.8104  \n",
       "5   1.0314  -3.6241   9.7670  12.5809  -4.7602  \n",
       "6   0.5845   9.1104   9.1143  10.8869  -3.2097  \n",
       "7  -0.3776   4.2178   9.4237   8.6624   3.4806  \n",
       "8  -1.9940  -1.0733   8.1975  19.5114   4.8453  \n",
       "9   0.4467  14.1287   7.9133  16.2375  14.2514  \n",
       "\n",
       "[10 rows x 201 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importing main necessary libraries for the project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display # to use display() for DataFrames\n",
    "\n",
    "# Reading the anonymous data\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "# Dropping ID_code since it's redundant given the dataframe index\n",
    "data.drop(\"ID_code\", axis=1, inplace=True)\n",
    "\n",
    "# Display first 10 observations\n",
    "display(data.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of customers: 200000\n",
      "Customers that will not make future transactions: 179902\n",
      "Customers that will make future transactions: 20098\n",
      "Percentage of customers tha will make future transactions: 10.049%\n"
     ]
    }
   ],
   "source": [
    "# Number of customers\n",
    "n_cust = data.shape[0]\n",
    "\n",
    "# Number of customers that will not make future transactions\n",
    "n_no_fut_trans = data[data[\"target\"] == 0].shape[0]\n",
    "\n",
    "# Number of customers that will make future transactions\n",
    "n_fut_trans = data[data[\"target\"] == 1].shape[0]\n",
    "\n",
    "print(\"Total number of customers: {}\".format(n_cust))\n",
    "print(\"Customers that will not make future transactions: {}\".format(n_no_fut_trans))\n",
    "print(\"Customers that will make future transactions: {}\".format(n_fut_trans))\n",
    "print(\"Percentage of customers tha will make future transactions: {}%\".format(n_fut_trans/n_cust*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points considered outliers in more than one feature: 1556\n",
      "Number of points considered outliers in some feature: 24896\n"
     ]
    }
   ],
   "source": [
    "# Outlier detection (Turkey's method)\n",
    "outliers_t  = []\n",
    "repeated = []\n",
    "\n",
    "# Features\n",
    "X = data.drop(['target'], axis = 1)\n",
    "\n",
    "# For each feature \n",
    "for feature in X.keys():\n",
    "    \n",
    "    # Calculate first quartile\n",
    "    Q1 = np.percentile(X[feature], 25)\n",
    "    \n",
    "    # Calculate\n",
    "    Q3 = np.percentile(X[feature], 75)\n",
    "    \n",
    "    # Calculate interquatile range * 1.5\n",
    "    step = (Q3-Q1)*1.5\n",
    "    \n",
    "    for i in list((X[~((X[feature] >= Q1 - step) & (X[feature] <= Q3 + step))]).index.values):\n",
    "        if i not in outliers_t:\n",
    "            outliers_t.append(i)\n",
    "        elif i not in repeated:\n",
    "            repeated.append(i)\n",
    "\n",
    "\n",
    "print(\"Number of points considered outliers in more than one feature: {}\".format(len(repeated)))\n",
    "print(\"Number of points considered outliers in some feature: {}\".format(len(outliers_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers that will not make future transactions: 178569\n",
      "Customers that will make future transactions: 19875\n",
      "Percentage of customers tha will make future transactions: 9.9375%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Dropping rows with outlier values in more than one feature\n",
    "filtered_data = data.drop(repeated)\n",
    "\n",
    "# Checking data distribution after outliers removal\n",
    "# Number of customers that will not make future transactions\n",
    "n_no_fut_trans = filtered_data[filtered_data[\"target\"] == 0].shape[0]\n",
    "# Number of customers that will make future transactions\n",
    "n_fut_trans = filtered_data[filtered_data[\"target\"] == 1].shape[0]\n",
    "\n",
    "print(\"Customers that will not make future transactions: {}\".format(n_no_fut_trans))\n",
    "print(\"Customers that will make future transactions: {}\".format(n_fut_trans))\n",
    "print(\"Percentage of customers tha will make future transactions: {}%\".format(n_fut_trans/n_cust*100))\n",
    "\n",
    "# Generating smote (oversampling) \n",
    "smt = SMOTE(random_state=42)\n",
    "\n",
    "# Generating StratifiedKFold Cross-validator\n",
    "n_folds = 10\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components after pca: 90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "filtered_features = filtered_data.drop('target', axis=1)\n",
    "filtered_targets= filtered_data[['target']].values\n",
    "\n",
    "# Applying pca to the filtered data\n",
    "pca = PCA(n_components=0.9, svd_solver='full').fit(filtered_features.reset_index(drop=True))\n",
    "\n",
    "# Checking number of components\n",
    "print(\"Number of components after pca: {}\".format(pca.n_components_))\n",
    "\n",
    "# Transforming data based on components\n",
    "transf_features = pca.transform(filtered_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection (Local Outlier Factor)\n",
    "# Not viable due to O(n²) complexity, takes too long as result of dataset size\n",
    "# Kept for future reference only\n",
    "\n",
    "# from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# lof = LocalOutlierFactor()\n",
    "\n",
    "# outliers_l = lof.fit_predict(X)\n",
    "\n",
    "# print(\"Number of points considered outliers: {}\".format(len(outliers_l[outliers_l == -1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, fbeta_score\n",
    "from time import time\n",
    "\n",
    "# Function used for the classifiers pipeline\n",
    "def train_predict(classifier, X_train, y_train, X_test, y_test, sample_size=-1):\n",
    "   \n",
    "    results = {}\n",
    "    \n",
    "    if(sample_size == -1):\n",
    "        sample_size = X_train.shape[0]\n",
    "        \n",
    "    start = time() # Get training start time\n",
    "    classifier = classifier.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    end = time() # Get training end time\n",
    "    \n",
    "    # Storing training time\n",
    "    results['train_time'] = end-start\n",
    "    \n",
    "    start = time() # Get predictions start time\n",
    "    predictions_test = classifier.predict(X_test)\n",
    "    predictions_train = classifier.predict(X_train)\n",
    "    end = time() # Get predictions end time\n",
    "    \n",
    "    results['pred_time'] = end-start\n",
    "    \n",
    "    # Compute area under the receive operating characterist curve using roc_auc_acore\n",
    "    results['roc_train'] = roc_auc_score(y_train, predictions_train)\n",
    "    results['roc_test'] = roc_auc_score(y_test, predictions_test)\n",
    "    \n",
    "    # Compute F-score using fbeta_score\n",
    "    results['f_train'] = fbeta_score(y_train, predictions_train, beta=2)\n",
    "    results['f_test'] = fbeta_score(y_test, predictions_test, beta=2)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code provided by udacity from machine learning engineer nanodegree project \n",
    "import matplotlib.pyplot as pl\n",
    "def evaluate(results, roc_auc, f1):\n",
    "    \"\"\"\n",
    "    Visualization code to display results of various learners.\n",
    "    \n",
    "    inputs:\n",
    "      - learners: a list of supervised learners\n",
    "      - stats: a list of dictionaries of the statistic results from 'train_predict()'\n",
    "      - accuracy: The score for the naive predictor\n",
    "      - f1: The score for the naive predictor\n",
    "    \"\"\"\n",
    "  \n",
    "    # Create figure\n",
    "    fig, ax = pl.subplots(2, 4, figsize = (11,7))\n",
    "\n",
    "    # Constants\n",
    "    bar_width = 0.3\n",
    "    colors = ['#A00000','#00A0A0','#00A000']\n",
    "    \n",
    "    # Super loop to plot four panels of data\n",
    "    for k, learner in enumerate(results.keys()):\n",
    "        for j, metric in enumerate(['train_time', 'roc_train', 'f_train', 'pred_time', 'roc_test', 'f_test']):\n",
    "            for i in np.arange(3):\n",
    "                \n",
    "                # Creative plot code\n",
    "                ax[j//3, j%3].bar(i+k*bar_width, results[learner][i][metric], width = bar_width, color = colors[k])\n",
    "                ax[j//3, j%3].set_xticks([0.45, 1.45, 2.45])\n",
    "                ax[j//3, j%3].set_xticklabels([\"1%\", \"10%\", \"100%\"])\n",
    "                ax[j//3, j%3].set_xlabel(\"Training Set Size\")\n",
    "                ax[j//3, j%3].set_xlim((-0.1, 3.0))\n",
    "    \n",
    "    # Add unique y-labels\n",
    "    ax[0, 0].set_ylabel(\"Time (in seconds)\")\n",
    "    ax[0, 1].set_ylabel(\"ROC AUC Score\")\n",
    "    ax[0, 2].set_ylabel(\"F-score\")\n",
    "    ax[1, 0].set_ylabel(\"Time (in seconds)\")\n",
    "    ax[1, 1].set_ylabel(\"ROC AUC Score\")\n",
    "    ax[1, 2].set_ylabel(\"F-score\")\n",
    "    \n",
    "    # Add titles\n",
    "    ax[0, 0].set_title(\"Model Training\")\n",
    "    ax[0, 1].set_title(\"ROC AUC on Training Subset\")\n",
    "    ax[0, 2].set_title(\"F-score on Training Subset\")\n",
    "    ax[1, 0].set_title(\"Model Predicting\")\n",
    "    ax[1, 1].set_title(\"ROC AUC Score on Testing Set\")\n",
    "    ax[1, 2].set_title(\"F-score on Testing Set\")\n",
    "    \n",
    "    # Add horizontal lines for naive predictors\n",
    "    ax[0, 1].axhline(y = roc_auc, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
    "    ax[1, 1].axhline(y = roc_auc, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
    "    ax[0, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
    "    ax[1, 2].axhline(y = f1, xmin = -0.1, xmax = 3.0, linewidth = 1, color = 'k', linestyle = 'dashed')\n",
    "    \n",
    "    # Set y-limits for score panels\n",
    "    ax[0, 1].set_ylim((0, 1))\n",
    "    ax[0, 2].set_ylim((0, 1))\n",
    "    ax[1, 1].set_ylim((0, 1))\n",
    "    ax[1, 2].set_ylim((0, 1))\n",
    "\n",
    "    # Set additional plots invisibles\n",
    "    ax[0, 3].set_visible(False)\n",
    "    ax[1, 3].axis('off')\n",
    "\n",
    "    # Create legend\n",
    "    for i, learner in enumerate(results.keys()):\n",
    "        pl.bar(0, 0, color=colors[i], label=learner)\n",
    "    pl.legend()\n",
    "    \n",
    "    # Aesthetics\n",
    "    pl.suptitle(\"Performance Metrics for Three Supervised Learning Models\", fontsize = 16, y = 1.10)\n",
    "    pl.tight_layout()\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def mean_result(results):\n",
    "    \n",
    "    final_results = defaultdict(dict)\n",
    "    \n",
    "    for clf, data in results.items():\n",
    "        classifier_data = data\n",
    "        \n",
    "        for size, values in classifier_data.items():\n",
    "            results = values\n",
    "            \n",
    "            train_time = 0.0\n",
    "            pred_time = 0.0\n",
    "            roc_train = 0.0\n",
    "            roc_test = 0.0\n",
    "            f_train = 0.0\n",
    "            f_test = 0.0\n",
    "            \n",
    "            for fold_result in results:\n",
    "                train_time += fold_result['train_time']\n",
    "                pred_time += fold_result['pred_time']\n",
    "                roc_train += fold_result['roc_train']\n",
    "                roc_test += fold_result['roc_test']\n",
    "                f_train += fold_result['f_train']\n",
    "                f_test += fold_result['f_test']\n",
    "            \n",
    "            train_time /= len(fold_result)\n",
    "            pred_time /= len(fold_result)\n",
    "            roc_train /= len(fold_result)\n",
    "            roc_test /= len(fold_result)\n",
    "            f_train /= len(fold_result)\n",
    "            f_test /= len(fold_result)\n",
    "            \n",
    "            result = {'train_time': train_time, 'pred_time': pred_time, \\\n",
    "                      'roc_train': roc_train, 'roc_test': roc_test, \\\n",
    "                      'f_train': f_train, 'f_test': f_test}\n",
    "            \n",
    "            final_results[clf][size] = result\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from collections import defaultdict\n",
    "\n",
    "clf_A = CatBoostClassifier(silent=True, eval_metric='AUC', early_stopping_rounds=500, \\\n",
    "                           task_type='GPU', od_type='Iter', random_state=42)\n",
    "clf_B = XGBClassifier()\n",
    "clf_C = GaussianNB()\n",
    "\n",
    "results = {}\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    results[clf_name] = defaultdict(lambda: [])\n",
    "    j = 0\n",
    "    for train_index, test_index in skf.split(transf_features, filtered_targets):\n",
    "\n",
    "        # Separating training and testing data\n",
    "        X_train, X_test = transf_features[train_index], transf_features[test_index]\n",
    "        y_train, y_test = filtered_targets[train_index], filtered_targets[test_index]\n",
    "\n",
    "        # Oversampling minor class\n",
    "        X_train, y_train = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "        size_1 = int(0.01 * X_train.shape[0])\n",
    "        size_10 =int(0.1 * X_train.shape[0])\n",
    "        size_100 = X_train.shape[0]\n",
    "\n",
    "        for i, samples in enumerate([size_1, size_10, size_100]):\n",
    "            results[clf_name][i].append(train_predict(clf, X_train, y_train, X_test, y_test, samples))\n",
    "        j += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating results mean\n",
    "final_results = mean_result(results)\n",
    "\n",
    "# Run metrics visualization for the three supervised learning models chosen\n",
    "evaluate(final_results, 0.8, 0.8)\n",
    "\n",
    "# Checking numeric values for each method used (complete training set)\n",
    "for clf in [clf_A, clf_B, clf_C]:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    print(\"{} \\n Time - Training: {} \\t Testing: {} \\n ROC AUC - Train: {} \\t Test: {} \\n F-Score: Train: {} \\t Test: {}\" \\\n",
    "          .format(clf_name, \\\n",
    "          final_results[clf_name][2]['train_time'],final_results[clf_name][2]['pred_time'], \\\n",
    "          final_results[clf_name][2]['roc_train'],final_results[clf_name][2]['roc_test'], \\\n",
    "          final_results[clf_name][2]['f_train'], final_results[clf_name][2]['f_test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "\n",
    "clf = CatBoostClassifier( eval_metric='AUC', iterations= 8000, \\\n",
    "                         task_type='GPU', od_type='Iter', random_state=42, \\\n",
    "                         loss_function='Logloss', max_depth=10, early_stopping_rounds=512, learning_rate=0.025)\n",
    "\n",
    "results_train = np.empty((0,0))\n",
    "results_test = np.empty((0,0))\n",
    "\n",
    "# reading data for kaggle submission\n",
    "submission_data = pd.read_csv('test.csv')\n",
    "\n",
    "pred_submission = 0\n",
    "\n",
    "submission_data.drop('ID_code', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(filtered_features, filtered_targets):\n",
    "\n",
    "        # Separating training and testing data\n",
    "        X_train, X_test = filtered_features.values[train_index], filtered_features.values[test_index]\n",
    "        y_train, y_test = filtered_targets[train_index], filtered_targets[test_index]\n",
    "\n",
    "        # Oversampling minor class\n",
    "        X_train, y_train = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Creating data Pool for classifier \n",
    "        train_data = Pool(X_train, label=y_train)\n",
    "        test_data = Pool(X_test, label=y_test[:,0])\n",
    "        \n",
    "        model = clf.fit(train_data, eval_set=test_data, use_best_model=True, verbose=400)\n",
    "        \n",
    "        predictions_train = model.predict_proba(X_train)[:,1]\n",
    "        predictions_test = model.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        train_auc = roc_auc_score(y_train, predictions_train)\n",
    "        test_auc = roc_auc_score(y_test, predictions_test)\n",
    "        \n",
    "        results_train = np.append(results_train, train_auc)\n",
    "        results_test = np.append(results_test, test_auc)\n",
    "        \n",
    "        pred_submission += model.predict_proba(submission_data)[:,1]\n",
    "        \n",
    "        print(\"ROC AUC: {}\".format(test_auc))\n",
    "\n",
    "pred_submission /= n_folds\n",
    "\n",
    "import winsound\n",
    "winsound.Beep(2500, 2000)\n",
    "# Report the before-and-afterscores\n",
    "# print(\"Unoptimized model\\n------\")\n",
    "# print(\"ROC AUC score on testing data: {:.4f}\".format(roc_auc_score(y_test, predictions)))\n",
    "# print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 2)))\n",
    "\n",
    "print(\"Average train ROC AUC: {}\".format(np.mean(results_train)))\n",
    "print(\"Average test ROC AUC: {}\".format(np.mean(results_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 2048 rounds.\n",
      "[2048]\ttraining's auc: 0.93603\tvalid_1's auc: 0.884768\n",
      "[4096]\ttraining's auc: 0.960809\tvalid_1's auc: 0.897763\n",
      "[6144]\ttraining's auc: 0.973274\tvalid_1's auc: 0.900741\n",
      "[8192]\ttraining's auc: 0.982257\tvalid_1's auc: 0.900912\n",
      "Early stopping, best iteration is:\n",
      "[7571]\ttraining's auc: 0.97979\tvalid_1's auc: 0.901322\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 2048 rounds.\n",
      "[2048]\ttraining's auc: 0.936937\tvalid_1's auc: 0.868495\n",
      "[4096]\ttraining's auc: 0.961131\tvalid_1's auc: 0.881015\n",
      "[6144]\ttraining's auc: 0.973533\tvalid_1's auc: 0.884205\n",
      "[8192]\ttraining's auc: 0.98215\tvalid_1's auc: 0.885604\n",
      "[10240]\ttraining's auc: 0.988556\tvalid_1's auc: 0.885737\n",
      "Early stopping, best iteration is:\n",
      "[8909]\ttraining's auc: 0.984672\tvalid_1's auc: 0.885952\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 2048 rounds.\n",
      "[2048]\ttraining's auc: 0.936067\tvalid_1's auc: 0.881449\n",
      "[4096]\ttraining's auc: 0.961019\tvalid_1's auc: 0.894317\n",
      "[6144]\ttraining's auc: 0.973603\tvalid_1's auc: 0.897355\n",
      "[8192]\ttraining's auc: 0.982023\tvalid_1's auc: 0.898128\n",
      "Early stopping, best iteration is:\n",
      "[7995]\ttraining's auc: 0.981311\tvalid_1's auc: 0.898329\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 2048 rounds.\n",
      "[2048]\ttraining's auc: 0.936937\tvalid_1's auc: 0.879568\n",
      "[4096]\ttraining's auc: 0.961153\tvalid_1's auc: 0.892104\n",
      "[6144]\ttraining's auc: 0.973577\tvalid_1's auc: 0.894312\n",
      "[8192]\ttraining's auc: 0.982108\tvalid_1's auc: 0.894852\n",
      "[10240]\ttraining's auc: 0.9886\tvalid_1's auc: 0.89459\n",
      "Early stopping, best iteration is:\n",
      "[8669]\ttraining's auc: 0.98384\tvalid_1's auc: 0.895039\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 2048 rounds.\n",
      "[2048]\ttraining's auc: 0.937382\tvalid_1's auc: 0.872252\n",
      "[4096]\ttraining's auc: 0.961418\tvalid_1's auc: 0.886041\n",
      "[6144]\ttraining's auc: 0.973806\tvalid_1's auc: 0.889395\n",
      "[8192]\ttraining's auc: 0.982107\tvalid_1's auc: 0.890632\n",
      "[10240]\ttraining's auc: 0.988628\tvalid_1's auc: 0.89138\n",
      "[12288]\ttraining's auc: 0.993071\tvalid_1's auc: 0.891212\n",
      "Early stopping, best iteration is:\n",
      "[10395]\ttraining's auc: 0.989012\tvalid_1's auc: 0.891548\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 2048 rounds.\n",
      "[2048]\ttraining's auc: 0.937116\tvalid_1's auc: 0.873674\n",
      "[4096]\ttraining's auc: 0.961461\tvalid_1's auc: 0.885465\n",
      "[6144]\ttraining's auc: 0.97365\tvalid_1's auc: 0.888804\n",
      "[8192]\ttraining's auc: 0.98213\tvalid_1's auc: 0.889642\n",
      "[10240]\ttraining's auc: 0.988683\tvalid_1's auc: 0.889761\n",
      "Early stopping, best iteration is:\n",
      "[9297]\ttraining's auc: 0.986016\tvalid_1's auc: 0.890184\n",
      "Fold 7\n",
      "Training until validation scores don't improve for 2048 rounds.\n",
      "[2048]\ttraining's auc: 0.93659\tvalid_1's auc: 0.880515\n",
      "[4096]\ttraining's auc: 0.961135\tvalid_1's auc: 0.891929\n",
      "[6144]\ttraining's auc: 0.97345\tvalid_1's auc: 0.895017\n",
      "[8192]\ttraining's auc: 0.981929\tvalid_1's auc: 0.895626\n",
      "[10240]\ttraining's auc: 0.988619\tvalid_1's auc: 0.895482\n",
      "Early stopping, best iteration is:\n",
      "[8230]\ttraining's auc: 0.982053\tvalid_1's auc: 0.895712\n",
      "Fold 8\n",
      "Training until validation scores don't improve for 2048 rounds.\n",
      "[2048]\ttraining's auc: 0.93651\tvalid_1's auc: 0.884516\n",
      "[4096]\ttraining's auc: 0.961148\tvalid_1's auc: 0.896525\n",
      "[6144]\ttraining's auc: 0.97303\tvalid_1's auc: 0.899777\n",
      "[8192]\ttraining's auc: 0.981977\tvalid_1's auc: 0.900587\n",
      "[10240]\ttraining's auc: 0.988682\tvalid_1's auc: 0.900447\n",
      "Early stopping, best iteration is:\n",
      "[9197]\ttraining's auc: 0.985557\tvalid_1's auc: 0.900979\n",
      "Fold 9\n",
      "Training until validation scores don't improve for 2048 rounds.\n",
      "[2048]\ttraining's auc: 0.936424\tvalid_1's auc: 0.877377\n",
      "[4096]\ttraining's auc: 0.96099\tvalid_1's auc: 0.89079\n",
      "[6144]\ttraining's auc: 0.973771\tvalid_1's auc: 0.895275\n",
      "[8192]\ttraining's auc: 0.982348\tvalid_1's auc: 0.895894\n",
      "Early stopping, best iteration is:\n",
      "[7246]\ttraining's auc: 0.978693\tvalid_1's auc: 0.89602\n",
      "Fold 10\n",
      "Training until validation scores don't improve for 2048 rounds.\n",
      "[2048]\ttraining's auc: 0.936947\tvalid_1's auc: 0.873632\n",
      "[4096]\ttraining's auc: 0.961587\tvalid_1's auc: 0.886003\n",
      "[6144]\ttraining's auc: 0.973854\tvalid_1's auc: 0.889363\n",
      "[8192]\ttraining's auc: 0.982357\tvalid_1's auc: 0.88996\n",
      "[10240]\ttraining's auc: 0.988763\tvalid_1's auc: 0.889937\n",
      "Early stopping, best iteration is:\n",
      "[8513]\ttraining's auc: 0.983488\tvalid_1's auc: 0.890159\n",
      "Overall train ROC AUC: 0.9834432189362412\n",
      "Overall test ROC AUC: 0.894524522634663\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "submission_data = pd.read_csv('test.csv')\n",
    "\n",
    "pred_submission = 0\n",
    "\n",
    "submission_data.drop('ID_code', axis=1, inplace=True)\n",
    "\n",
    "results_train = np.empty((0,0))\n",
    "results_test = np.empty((0,0))\n",
    "\n",
    "for index, (train_index, test_index) in enumerate(skf.split(filtered_features, filtered_targets)):\n",
    "    \n",
    "        print(\"Fold {}\".format(index+1))\n",
    "        # Separating training and testing data\n",
    "        X_train, X_test = filtered_features.values[train_index], filtered_features.values[test_index]\n",
    "        y_train, y_test = filtered_targets[train_index], filtered_targets[test_index]\n",
    "\n",
    "        # Oversampling minor class\n",
    "#         X_train, y_train = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Creating dataset for classifier \n",
    "        train_data = lgb.Dataset(X_train, label=y_train[:,0])\n",
    "        test_data = lgb.Dataset(X_test, label=y_test[:,0])\n",
    "        \n",
    "        param = {'random_state':42, 'metric': 'auc', 'bagging_freq': 5, 'bagging_fraction': 0.35, 'max_depth': 7,\n",
    "                 'min_data_in_leaf': 256, 'learning_rate': 0.005, 'objective': 'binary', 'max_leaves': 80,\n",
    "                 'num_threads': 4, 'is_unbalance': True}\n",
    "        model = lgb.train(param, train_data, 100000, valid_sets = [train_data, test_data], early_stopping_rounds=2048,verbose_eval=2048)\n",
    "        \n",
    "        predictions_train = model.predict(X_train, num_iteration=model.best_iteration)\n",
    "        predictions_test = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "        \n",
    "        train_auc = roc_auc_score(y_train, predictions_train)\n",
    "        test_auc = roc_auc_score(y_test, predictions_test)\n",
    "        \n",
    "        results_train = np.append(results_train, train_auc)\n",
    "        results_test = np.append(results_test, test_auc)\n",
    "        \n",
    "        pred_submission += model.predict(submission_data, num_iteration=model.best_iteration)/n_folds\n",
    "        \n",
    "print(\"Overall train ROC AUC: {}\".format(np.mean(results_train)))\n",
    "print(\"Overall test ROC AUC: {}\".format(np.mean(results_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission['target'] = pred_submission\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
